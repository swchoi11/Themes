{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "target_file = './resource/test/fail2_issue_0.png'\n",
    "img = cv2.imread(target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def _hsv_color( component_img: np.ndarray):\n",
    "    if len(component_img.shape) == 3:\n",
    "        img_rgb = cv2.cvtColor(component_img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        img_rgb = component_img\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # h channel main color\n",
    "    h_channel = img_hsv[:, :, 0]\n",
    "    hist_h = cv2.calcHist([h_channel], [0], None, [180], [0, 180])\n",
    "\n",
    "    # find peaks\n",
    "    peaks = []\n",
    "    for i in range(1, len(hist_h) - 1):\n",
    "        if hist_h[i] > hist_h[i-1] and hist_h[i] > hist_h[i+1] and hist_h[i] > np.max(hist_h) * 0.1:\n",
    "            peaks.append(i)\n",
    "    \n",
    "    # select peaks\n",
    "    peaks = sorted(peaks, key=lambda x: hist_h[x], reverse=True)[:3]\n",
    "\n",
    "    # find colors\n",
    "    colors = []\n",
    "    for peak_h in peaks:\n",
    "        mask = np.abs(h_channel - peak_h) < 10\n",
    "        if np.any(mask):\n",
    "            masked_pixels = img_rgb[mask]\n",
    "            if len(masked_pixels) > 0:\n",
    "                avg_color = np.mean(masked_pixels, axis=0).astype(int)\n",
    "                colors.append(avg_color.tolist())\n",
    "    \n",
    "    # HSV에서 충분한 색상을 찾지 못한 경우 KMeans로 보완\n",
    "    if len(colors) < 3:\n",
    "        pixels_reshaped = img_rgb.reshape(-1, 3)\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "        kmeans.fit(pixels_reshaped)\n",
    "\n",
    "        for center in kmeans.cluster_centers_:\n",
    "            if len(colors) < 3:\n",
    "                colors.append(center.astype(int).tolist())\n",
    "    \n",
    "    return colors[:3]\n",
    "\n",
    "def _lab_color( component_img: np.ndarray):\n",
    "    if len(component_img.shape) == 3:\n",
    "        img_rgb = cv2.cvtColor(component_img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        img_rgb = component_img\n",
    "\n",
    "    # lab\n",
    "    img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    # a, b channel \n",
    "    a_channel = img_lab[:, :, 1]\n",
    "    b_channel = img_lab[:, :, 2]\n",
    "\n",
    "    # histogram\n",
    "    hist_ab = cv2.calcHist([a_channel, b_channel], [0, 1], None, [32, 32], [0, 256, 0, 256])\n",
    "\n",
    "    # find peaks\n",
    "    peaks = []\n",
    "    threshold = np.max(hist_ab) * 0.05\n",
    "\n",
    "    for i in range(1, hist_ab.shape[0] - 1):\n",
    "        for j in range(1, hist_ab.shape[1] - 1):\n",
    "            if (hist_ab[i, j] > threshold and \n",
    "                hist_ab[i, j] > hist_ab[i-1, j] and hist_ab[i, j] > hist_ab[i+1, j] and\n",
    "                hist_ab[i, j] > hist_ab[i, j-1] and hist_ab[i, j] > hist_ab[i, j+1]):\n",
    "                peaks.append((i, j, hist_ab[i, j]))\n",
    "\n",
    "    peaks = sorted(peaks, key=lambda x: x[2], reverse=True)[:3]\n",
    "\n",
    "    #find colors\n",
    "    colors = []\n",
    "    for a_bin, b_bin, _ in peaks:\n",
    "        a_center = a_bin * 8\n",
    "        b_center = b_bin * 8\n",
    "\n",
    "        a_mask = np.abs(a_channel - a_center) < 12\n",
    "        b_mask = np.abs(b_channel - b_center) < 12\n",
    "        region_mask = a_mask & b_mask\n",
    "\n",
    "        if np.any(region_mask):\n",
    "            region_pixels = img_rgb[region_mask]\n",
    "            avg_color = np.mean(region_pixels, axis=0).astype(int)\n",
    "            colors.append(avg_color.tolist())\n",
    "\n",
    "    # LAB에서 충분한 색상을 찾지 못한 경우 KMeans로 보완\n",
    "    if len(colors) < 3:\n",
    "        pixels_reshaped = img_rgb.reshape(-1, 3)\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "        kmeans.fit(pixels_reshaped)\n",
    "\n",
    "        for center in kmeans.cluster_centers_:\n",
    "            if len(colors) < 3:\n",
    "                colors.append(center.astype(int).tolist())\n",
    "\n",
    "    return colors[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def color_extraction(component_img: np.ndarray):\n",
    "    if len(component_img.shape) == 3:\n",
    "        img_rgb = cv2.cvtColor(component_img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        img_rgb = component_img\n",
    "    \n",
    "    # 이미지 특성 분석\n",
    "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(img_hsv)\n",
    "\n",
    "    # 고채도 픽셀 비율\n",
    "    high_saturation_ratio = np.sum(s > 50) / s.size\n",
    "\n",
    "    print(f\"고채도 픽셀 비율: {high_saturation_ratio}\")\n",
    "\n",
    "    if high_saturation_ratio < 0.3:\n",
    "        print(\"LAB 색공간 사용\")\n",
    "        colors = _lab_color(img_rgb)\n",
    "    else:\n",
    "        print(\"HSV 색공간 사용\")\n",
    "        colors = _hsv_color(component_img)\n",
    "    \n",
    "    print(f\"추출된 색상 개수: {len(colors)}\")\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고채도 픽셀 비율: 0.9037339226018472\n",
      "HSV 색공간 사용\n",
      "추출된 색상 개수: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[93, 66, 42], [88, 64, 40], [114, 79, 50]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_extraction(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "paddle_ocr = PaddleOCR(\n",
    "        det_model_dir='./src/weights/en_PP-OCRv3_det_infer',\n",
    "        rec_model_dir='./src/weights/en_PP-OCRv3_rec_infer', \n",
    "        cls_model_dir='./src/weights/ch_ppocr_mobile_v2.0_cls_infer',\n",
    "        lang='en',\n",
    "        use_angle_cls=False,\n",
    "        use_gpu=False,\n",
    "        show_log=False)\n",
    "\n",
    "def _extract_darkest_color(component_img: np.ndarray) -> tuple:\n",
    "    hsv = cv2.cvtColor(component_img, cv2.COLOR_BGR2HSV)\n",
    "    dark_color = np.min(hsv, axis=0)\n",
    "    return dark_color\n",
    "\n",
    "def _extract_brightest_color(component_img: np.ndarray) -> tuple:\n",
    "    hsv = cv2.cvtColor(component_img, cv2.COLOR_BGR2HSV)\n",
    "    bright_color = np.max(hsv, axis=0)\n",
    "    return bright_color\n",
    "\n",
    "def _color_diff(color1: tuple, color2: tuple) -> float:\n",
    "    return np.linalg.norm(np.array(color1) - np.array(color2))\n",
    "\n",
    "def extract_text_color(img: np.ndarray):\n",
    "    text = paddle_ocr.ocr(img, cls=False)\n",
    "    print(text)\n",
    "\n",
    "    if text is None or len(text) == 0:\n",
    "        dark = _extract_darkest_color(img)\n",
    "        bright = _extract_brightest_color(img)\n",
    "        diff = _color_diff(dark, bright)\n",
    "        print(f\"text_color: {dark}, {bright}, {diff}\")\n",
    "        return diff\n",
    "\n",
    "    text_pixels = []\n",
    "\n",
    "    for item in text:\n",
    "        coords, (text, confidence) = item\n",
    "        if confidence > 0.6:\n",
    "            coords_array = np.array(coords, dtype=np.int32)\n",
    "            text_bbox = cv2.boundingRect(coords_array)\n",
    "            tx, ty, tw, th = text_bbox\n",
    "            text_region = img[ty:ty+th, tx:tx+tw]\n",
    "            text_pixel = text_region.reshape(-1, 3)\n",
    "            text_pixels.append(text_pixel)\n",
    "\n",
    "    if len(text_pixels) == 0:\n",
    "        dark = _extract_darkest_color(img)\n",
    "        bright = _extract_brightest_color(img)\n",
    "        diff = _color_diff(dark, bright)\n",
    "        print(f\"text_color: {dark}, {bright}, {diff}\")\n",
    "        return diff\n",
    "\n",
    "    text_pixels = np.array(text_pixels)\n",
    "    text_color = color_extraction(text_pixels)\n",
    "\n",
    "    return text_color\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mextract_text_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mextract_text_color\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m     36\u001b[39m text_pixels = []\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     coords, (text, confidence) = item\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m confidence > \u001b[32m0.6\u001b[39m:\n\u001b[32m     41\u001b[39m         coords_array = np.array(coords, dtype=np.int32)\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "extract_text_color(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "themes-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
